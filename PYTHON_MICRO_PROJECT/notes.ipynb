{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8df19d33",
   "metadata": {},
   "source": [
    "# Detailed Summary of `model.py`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab3ee3f8",
   "metadata": {},
   "source": [
    "This notebook provides a detailed explanation of the `model.py` script, including the libraries used, their purposes, and where they are applied in the code. Special emphasis is given to **Pandas**, **NumPy**, and **Scikit-learn**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9bfa95f",
   "metadata": {},
   "source": [
    "## Libraries Used"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f1dba56",
   "metadata": {},
   "source": [
    "### 1. **Pandas**\n",
    "**Purpose**: Pandas is used for data manipulation and analysis. It provides data structures like `DataFrame` and `Series` for handling structured data.\n",
    "\n",
    "**Where It Is Used**:\n",
    "- **File Reading**:\n",
    "  - `pd.read_csv()` is used to load datasets from CSV files.\n",
    "  ```python\n",
    "  df = pd.read_csv('csv_files/transaction_dataset.csv', index_col=0)\n",
    "  ```\n",
    "- **Data Cleaning**:\n",
    "  - Dropping categorical columns:\n",
    "    ```python\n",
    "    categories = df.select_dtypes('O').columns\n",
    "    df.drop(df[categories], axis=1, inplace=True)\n",
    "    ```\n",
    "  - Filling missing values with the median:\n",
    "    ```python\n",
    "    df.fillna(df.median(), inplace=True)\n",
    "    ```\n",
    "  - Removing zero-variance features:\n",
    "    ```python\n",
    "    no_var = df.var() == 0\n",
    "    df.drop(df.var()[no_var].index, axis=1, inplace=True)\n",
    "    ```\n",
    "- **Feature Engineering**:\n",
    "  - Dropping redundant or less important features:\n",
    "    ```python\n",
    "    drop_existing = [col for col in drop if col in df.columns]\n",
    "    df.drop(drop_existing, axis=1, inplace=True)\n",
    "    ```\n",
    "- **DataFrame Operations**:\n",
    "  - Splitting features (`X`) and target (`y`):\n",
    "    ```python\n",
    "    y = df['FLAG']\n",
    "    X = df.drop('FLAG', axis=1)\n",
    "    ```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8477503d",
   "metadata": {},
   "source": [
    "**Why It Is Important**:\n",
    "- Simplifies data preprocessing, cleaning, and manipulation.\n",
    "- Provides intuitive syntax for handling structured data, making it easier to prepare datasets for training and testing."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67910e22",
   "metadata": {},
   "source": [
    "### 2. **NumPy**\n",
    "**Purpose**: NumPy is used for numerical computing and array operations.\n",
    "\n",
    "**Where It Is Used**:\n",
    "- **Array Operations**:\n",
    "  - Converting Pandas DataFrames to NumPy arrays for model training:\n",
    "    ```python\n",
    "    norm_train_f = norm.fit_transform(X_train)\n",
    "    norm_test_f = norm.transform(X_test)\n",
    "    ```\n",
    "- **Statistical Operations**:\n",
    "  - Calculating the median for missing value imputation:\n",
    "    ```python\n",
    "    df.fillna(df.median(), inplace=True)\n",
    "    ```\n",
    "  - Counting class distributions:\n",
    "    ```python\n",
    "    np.bincount(y_train)\n",
    "    np.bincount(y_tr_resample)\n",
    "    ```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1657ea26",
   "metadata": {},
   "source": [
    "**Why It Is Important**:\n",
    "- Provides the foundation for numerical operations in Python.\n",
    "- Enables efficient handling of large datasets and is tightly integrated with Scikit-learn."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88796508",
   "metadata": {},
   "source": [
    "### 3. **Scikit-learn**\n",
    "**Purpose**: Scikit-learn is used for machine learning tasks, including preprocessing, model training, and evaluation.\n",
    "\n",
    "**Where It Is Used**:\n",
    "- **Data Preprocessing**:\n",
    "  - Splitting the dataset into training and testing sets:\n",
    "    ```python\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4, random_state=123)\n",
    "    ```\n",
    "  - Normalizing features using `PowerTransformer`:\n",
    "    ```python\n",
    "    norm = PowerTransformer()\n",
    "    norm_train_f = norm.fit_transform(X_train)\n",
    "    norm_test_f = norm.transform(X_test)\n",
    "    ```\n",
    "- **Handling Class Imbalance**:\n",
    "  - Applying SMOTE to balance the dataset:\n",
    "    ```python\n",
    "    oversample = SMOTE()\n",
    "    x_tr_resample, y_tr_resample = oversample.fit_resample(norm_train_f, y_train)\n",
    "    ```\n",
    "- **Model Training**:\n",
    "  - Training a Random Forest classifier:\n",
    "    ```python\n",
    "    RF = RandomForestClassifier(random_state=42, n_estimators=100)\n",
    "    RF.fit(x_tr_resample, y_tr_resample)\n",
    "    ```\n",
    "- **Model Evaluation**:\n",
    "  - Generating classification reports and confusion matrices:\n",
    "    ```python\n",
    "    print(classification_report(y_test, preds_RF))\n",
    "    print(confusion_matrix(y_test, preds_RF))\n",
    "    ```\n",
    "  - Calculating the ROC AUC score:\n",
    "    ```python\n",
    "    print(roc_auc_score(y_test, preds_RF))\n",
    "    ```\n",
    "- **Feature Importance**:\n",
    "  - Extracting and visualizing feature importance:\n",
    "    ```python\n",
    "    feature_importance = pd.DataFrame({\n",
    "        'Feature': X.columns,\n",
    "        'Importance': RF.feature_importances_\n",
    "    }).sort_values(by='Importance', ascending=False)\n",
    "    ```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f5680d7",
   "metadata": {},
   "source": [
    "**Why It Is Important**:\n",
    "- Provides a comprehensive set of tools for building and evaluating machine learning models.\n",
    "- Integrates seamlessly with Pandas and NumPy, enabling efficient data preprocessing and model training."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "521318bd",
   "metadata": {},
   "source": [
    "### 4. **Matplotlib**\n",
    "**Purpose**: Matplotlib is used for creating static, interactive, and animated visualizations.\n",
    "\n",
    "**Where It Is Used**:\n",
    "- **Pie Charts**:\n",
    "  - Visualizing class distribution before and after SMOTE:\n",
    "    ```python\n",
    "    plt.pie(fraud_nonfraud_before, labels=['Non-Fraud', 'Fraud'], autopct='%1.1f%%', startangle=90, colors=['skyblue', 'orange'])\n",
    "    plt.pie(fraud_nonfraud_after, labels=['Non-Fraud', 'Fraud'], autopct='%1.1f%%', startangle=90, colors=['skyblue', 'orange'])\n",
    "    ```\n",
    "- **Bar Charts**:\n",
    "  - Visualizing feature importance:\n",
    "    ```python\n",
    "    sns.barplot(x='Importance', y='Feature', data=feature_importance.head(10))\n",
    "    ```\n",
    "- **Saving Figures**:\n",
    "  - Saving visualizations to the `images` directory:\n",
    "    ```python\n",
    "    plt.savefig('images/fraud_distribution_before_smote.png')\n",
    "    plt.savefig('images/fraud_distribution_after_smote.png')\n",
    "    plt.savefig('images/feature_importance.png')\n",
    "    ```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2df76b72",
   "metadata": {},
   "source": [
    "### 5. **Seaborn**\n",
    "**Purpose**: Seaborn is used for statistical data visualization.\n",
    "\n",
    "**Where It Is Used**:\n",
    "- **Bar Charts**:\n",
    "  - Used for plotting feature importance:\n",
    "    ```python\n",
    "    sns.barplot(x='Importance', y='Feature', data=feature_importance.head(10))\n",
    "    ```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "853ecb46",
   "metadata": {},
   "source": [
    "### 6. **Pickle**\n",
    "**Purpose**: Pickle is used for serializing and deserializing Python objects.\n",
    "\n",
    "**Where It Is Used**:\n",
    "- **Saving Models**:\n",
    "  - Saving the trained Random Forest model:\n",
    "    ```python\n",
    "    with open('models/ethereum_fraud_model.pkl', 'wb') as file:\n",
    "        pickle.dump(RF, file)\n",
    "    ```\n",
    "- **Saving Scalers**:\n",
    "  - Saving the `PowerTransformer` scaler:\n",
    "    ```python\n",
    "    with open('models/ethereum_fraud_scaler.pkl', 'wb') as file:\n",
    "        pickle.dump(norm, file)\n",
    "    ```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08adc0d4",
   "metadata": {},
   "source": [
    "### 7. **Imbalanced-learn (SMOTE)**\n",
    "**Purpose**: Imbalanced-learn is used to handle imbalanced datasets by oversampling the minority class.\n",
    "\n",
    "**Where It Is Used**:\n",
    "- **Balancing Classes**:\n",
    "  - Applying SMOTE to the training data:\n",
    "    ```python\n",
    "    oversample = SMOTE()\n",
    "    x_tr_resample, y_tr_resample = oversample.fit_resample(norm_train_f, y_train)\n",
    "    ```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fba0917",
   "metadata": {},
   "source": [
    "## Summary of Key Libraries\n",
    "| **Library**      | **Purpose**                                                                                     | **Where It Is Used**                                                                                     |\n",
    "|-------------------|-----------------------------------------------------------------------------------------------|----------------------------------------------------------------------------------------------------------|\n",
    "| **Pandas**        | Data manipulation and analysis.                                                               | Reading CSV files, cleaning data, feature engineering, creating DataFrames for results.                 |\n",
    "| **NumPy**         | Numerical computing and array operations.                                                     | Handling numerical data, statistical operations, and integration with Scikit-learn.                     |\n",
    "| **Scikit-learn**  | Machine learning tools for preprocessing, training, and evaluation.                           | Splitting data, normalizing features, applying SMOTE, training models, and evaluating performance.       |\n",
    "| **Matplotlib**    | Creating visualizations.                                                                      | Pie charts for class distribution, bar charts for feature importance, and saving figures.               |\n",
    "| **Seaborn**       | Statistical data visualization.                                                               | Plotting feature importance.                                                                             |\n",
    "| **Pickle**        | Serializing and deserializing Python objects.                                                 | Saving and loading models and scalers.                                                                   |\n",
    "| **Imbalanced-learn** | Handling imbalanced datasets.                                                              | Applying SMOTE to balance the dataset.                                                                   |"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
